{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qutrit Quantum Kernel with Classical Support Vector Machine (SVM) for Iris Dataset\n",
    "\n",
    "In this notebook, is the implementation of a quantum kernel combined with a classical SVM approach to tackle the Iris dataset. The Iris dataset is a well-known multi-class classification problem, consisting of samples from three different classes of iris flowers.\n",
    "\n",
    "The implementation process involves data preprocessing, quantum feature mapping, classical SVM training, and evaluation. In this particular architecture two qutrits are going to be used instead of only a single qutrit as in the binary classification problems.\n",
    "\n",
    "I'll import the necessary libraries at the beginning of the notebook to facilitate a smooth and efficient workflow. Let's proceed with building and evaluating the Qutrit Quantum Kernel combined with the classical SVM on the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.linalg import expm\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_moons\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qutrits\n",
    "\n",
    "Defining the qutrits that have three possible states, denoted as |0⟩, |1⟩, and |2⟩. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the qutrit states as column vectors\n",
    "q0 = np.array([[1], [0], [0]])\n",
    "q1 = np.array([[0], [1], [0]])\n",
    "q2 = np.array([[0], [0], [1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gell-Mann Matrices\n",
    "\n",
    "The generators of a qutrit are the operators that generate transformations on the qutrit states under some symmetry group. One common set of generators for a qutrit are the Gell-Mann matrices, which are a set of 8 Hermitian operators that span the space of 3x3 complex matrices:\n",
    "\n",
    "$gm1 = |0⟩⟨1| + |1⟩⟨0| \\\\\n",
    "gm2 = -i(|0⟩⟨1| - |1⟩⟨0|) \\\\\n",
    "gm3 = |0⟩⟨0| - |1⟩⟨1| \\\\\n",
    "gm4 = |0⟩⟨2| + |2⟩⟨0| \\\\\n",
    "gm5 = -i(|0⟩⟨2| - |2⟩⟨0|) \\\\\n",
    "gm6 = |1⟩⟨2| + |2⟩⟨1| \\\\\n",
    "gm7 = -i(|1⟩⟨2| - |2⟩⟨1|) \\\\\n",
    "gm8 = 1/√3 (|0⟩⟨0| + |1⟩⟨1| - 2|2⟩⟨2|)$\n",
    "\n",
    "These generators satisfy the commutation relations of the SU(3) Lie algebra, which is the symmetry group of the qutrit. The Gell-Mann matrices can be used to construct any unitary transformation on the qutrit, making them a useful tool for analyzing the behavior of qutrit systems in quantum mechanics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57735027  0.          0.        ]\n",
      " [ 0.          0.57735027  0.        ]\n",
      " [ 0.          0.         -1.15470054]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Gell-Mann matrices\n",
    "gm1 = np.kron(q0, q1.T) + np.kron(q1, q0.T)\n",
    "gm2 = -1j * (np.kron(q0, q1.T) - np.kron(q1, q0.T))\n",
    "gm3 = np.kron(q0, q0.T) - np.kron(q1, q1.T)\n",
    "gm4 = np.kron(q0, q2.T) + np.kron(q2, q0.T)\n",
    "gm5 = -1j * (np.kron(q0, q2.T) - np.kron(q2, q0.T))\n",
    "gm6 = np.kron(q1, q2.T) + np.kron(q2, q1.T)\n",
    "gm7 = -1j * (np.kron(q1, q2.T) - np.kron(q2, q1.T))\n",
    "gm8 = 1/np.sqrt(3) * (np.kron(q0, q0.T) + np.kron(q1, q1.T) - 2*np.kron(q2, q2.T))\n",
    "\n",
    "# Collect the Glenn-Mann matrices in a list\n",
    "generators = [gm1, gm2, gm3, gm4, gm5, gm6, gm7, gm8]\n",
    "\n",
    "# Print Glenn-Mann 8\n",
    "print(gm8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then defining the Hadamard operator for qutrits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadamard operator for qutrits:\n",
      "[[ 0.57735027+0.j   0.57735027+0.j   0.57735027+0.j ]\n",
      " [ 0.57735027+0.j  -0.28867513+0.5j -0.28867513-0.5j]\n",
      " [ 0.57735027+0.j  -0.28867513-0.5j -0.28867513+0.5j]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Hadamard operator for qutrits\n",
    "H = (1/np.sqrt(3)) * np.array([[1, 1, 1], [1, np.exp(2j*np.pi/3), np.exp(-2j*np.pi/3)], [1, np.exp(-2j*np.pi/3), np.exp(2j*np.pi/3)]])\n",
    "\n",
    "# Print the Hadamard operator\n",
    "print(\"Hadamard operator for qutrits:\")\n",
    "print(H)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Kernel\n",
    "\n",
    "To construct the quantum kernel, I'll use custom functions that leverage the principles of quantum computing to transform the input data into a high-dimensional Hilbert space. The quantum kernel captures complex and non-linear relationships between data points, making it advantageous for certain types of datasets, such as those with intricate decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding four features on a qutrit\n",
    "def encoding(vector):\n",
    "\n",
    "    sum = 0\n",
    "    for i in range(4):\n",
    "        sum = sum + (1j * vector[i] * generators[i]) \n",
    "\n",
    "    return np.dot(expm(sum), np.dot(H,q0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing to see if the encoding works with a simple vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.68960068-2.82036151e-01j]\n",
      " [ 0.35344573-1.85741072e-01j]\n",
      " [ 0.53430595-2.00022498e-04j]]\n",
      "[[-0.65299607+0.02265479j]\n",
      " [ 0.47112451+0.07255427j]\n",
      " [ 0.5880902 -0.00322283j]]\n",
      "multi\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "vector = np.array([6.34, 22.11, 2,3], dtype=complex)\n",
    "vector2 = np.array([-6.34, 22.11, 1, 4], dtype=complex)\n",
    "\n",
    "print(encoding(vector))\n",
    "print(encoding(vector2))\n",
    "print(\"multi\")\n",
    "print(np.real(np.dot(encoding(vector).conj().T, encoding(vector))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then defining the LZZ2 gate which is going to be used as an entanglement operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0. -2.]]\n",
      "[[ 4.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -4.  0.  0. -0.  0.  0. -0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -0.  0.  0. -0.  0.  0. -0.]\n",
      " [ 0.  0.  0.  0.  0.  0. -4. -0. -0.]\n",
      " [ 0.  0.  0.  0.  0.  0. -0. -0. -0.]\n",
      " [ 0.  0. -0.  0.  0. -0. -0. -0.  4.]]\n"
     ]
    }
   ],
   "source": [
    "LZ2 = gm3 + np.sqrt(3)*gm8\n",
    "LZZ2 = np.kron(LZ2, LZ2)\n",
    "print(LZ2)\n",
    "print(LZZ2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then defining the kernel function, which quantifies the similarity or correlation between the quantum states of x1 and x2 and serves as a critical component in quantum machine learning algorithms like Support Vector Machines (SVM) for classification tasks, where the quantum advantage lies in capturing non-linear relationships between data points in high-dimensional quantum spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kernel(x1, x2):\n",
    "    \"\"\"The quantum kernel.\"\"\"\n",
    "    qutrit_1 = encoding(x1)\n",
    "    qutrit_2 = encoding(x1)\n",
    "\n",
    "    # Entanglement gate\n",
    "    entangle_gate = 1j*LZZ2\n",
    "\n",
    "    # Applying entanglement between the three qutrits\n",
    "    qutrit_1x2 = np.kron(qutrit_1, qutrit_2)\n",
    "    kron1 = np.dot(expm(entangle_gate), qutrit_1x2)\n",
    "\n",
    "    qutrit_1 = encoding(x2)\n",
    "    qutrit_2 = encoding(x2)\n",
    "\n",
    "    # Applying entanglement between the three qutrits\n",
    "    qutrit_1x2 = np.kron(qutrit_1, qutrit_2)\n",
    "    kron2 = np.dot(expm(entangle_gate), qutrit_1x2)\n",
    "\n",
    "    return np.real(np.dot(kron1.conj().T, kron2)**2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6505781279663496\n"
     ]
    }
   ],
   "source": [
    "print(kernel(vector, vector2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000, dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(kernel(vector, vector), requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kernel_matrix(A, B):\n",
    "    \"\"\"Compute the matrix whose entries are the kernel\n",
    "       evaluated on pairwise data from sets A and B.\"\"\"\n",
    "    return np.array([[kernel(a, b) for b in B] for a in A])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris dataset\n",
    "\n",
    "Each sample in the Iris dataset is characterized by four features: sepal length, sepal width, petal length, and petal width, all measured in centimeters. The goal of this classification task is to predict the species of the iris flower based on these four features. In the dataset ingestion step, we'll load the Iris dataset using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (150, 4)\n",
      "Shape of y: (150,)\n",
      "x[0] feature example:  [-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
      "y[0]:  3.0\n"
     ]
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# scaling the inputs is important since the embedding we use is periodic\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "y_scaled = 2 * (y - 0.5)\n",
    "\n",
    "print('Shape of X:', X_scaled.shape)\n",
    "print('Shape of y:', y_scaled.shape)\n",
    "print('x[0] feature example: ', X_scaled[0])\n",
    "print('y[0]: ', y_scaled[142])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the dataset into a training set and a test set into a 80-20 train-test split with equal representation of the two classes in both sets, I'll use the train_test_split function from sklearn.model_selection module with the stratify parameter set to the target variable y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts in training set: 120\n",
      "Class counts in test set: 30\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, stratify=y_scaled, random_state=42)\n",
    "\n",
    "# Use np.sum to count the number of instances of each class in both sets\n",
    "print(\"Class counts in training set:\", np.sum(y_train.shape))\n",
    "print(\"Class counts in test set:\", np.sum(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000013\n"
     ]
    }
   ],
   "source": [
    "print(kernel(X_train[0], X_train[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical SVM\n",
    "\n",
    "For the classical SVM component, I'll rely on the popular scikit-learn library, a powerful toolset for machine learning in Python. The SVM aims to find the optimal hyperplane that separates data points of different classes while maximizing the margin between them. By combining the quantum kernel with the classical SVM, we can handle multi-class classification tasks effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm = SVC(kernel=kernel_matrix).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svm.predict(X_test)\n",
    "accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results\n",
      "_____________________________________________\n",
      "\n",
      "Recall: 90.00%\n",
      "Precision: 92.31%\n",
      "Accuracy: 90.00%\n",
      "Macro Averaged F1-score: 89.77%\n",
      "_____________________________________________\n"
     ]
    }
   ],
   "source": [
    "# To be printed better\n",
    "y_pred = predictions\n",
    "y_true = y_test\n",
    "accuracy = accuracy_score(y_true, y_pred)* 100\n",
    "f1 = f1_score(y_true, y_pred, average='macro')* 100\n",
    "precision = precision_score(y_true, y_pred, average='macro')* 100\n",
    "recall = recall_score(y_true, y_pred, average='macro')* 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation Results\")\n",
    "print(\"_____________________________________________\")\n",
    "print(\n",
    "            f\"\\nRecall: {recall:.2f}%\"\n",
    "            f\"\\nPrecision: {precision:.2f}%\"\n",
    "            f\"\\nAccuracy: {accuracy:.2f}%\"\n",
    "            f\"\\nMacro Averaged F1-score: {f1:.2f}%\"\n",
    "            )\n",
    "print(\"_____________________________________________\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
