{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qutrit Quantum Kernel with Classical Support Vector Machine (SVM) for Glass Dataset\n",
    "\n",
    "In this notebook, I demonstrate the utilization of a quantum kernel in conjunction with a classical SVM approach to handle the Glass dataset. The Glass dataset is a multi-class classification problem containing samples of different types of glass. To address this classification task, we'll follow a systematic implementation approach, involving data preprocessing, quantum feature mapping, classical SVM training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.linalg import expm\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_moons\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qutrits\n",
    "\n",
    "Defining the qutrits that have three possible states, denoted as |0⟩, |1⟩, and |2⟩. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the qutrit states as column vectors\n",
    "q0 = np.array([[1], [0], [0]])\n",
    "q1 = np.array([[0], [1], [0]])\n",
    "q2 = np.array([[0], [0], [1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gell-Mann Matrices\n",
    "\n",
    "The generators of a qutrit are the operators that generate transformations on the qutrit states under some symmetry group. One common set of generators for a qutrit are the Gell-Mann matrices, which are a set of 8 Hermitian operators that span the space of 3x3 complex matrices:\n",
    "\n",
    "$gm1 = |0⟩⟨1| + |1⟩⟨0| \\\\\n",
    "gm2 = -i(|0⟩⟨1| - |1⟩⟨0|) \\\\\n",
    "gm3 = |0⟩⟨0| - |1⟩⟨1| \\\\\n",
    "gm4 = |0⟩⟨2| + |2⟩⟨0| \\\\\n",
    "gm5 = -i(|0⟩⟨2| - |2⟩⟨0|) \\\\\n",
    "gm6 = |1⟩⟨2| + |2⟩⟨1| \\\\\n",
    "gm7 = -i(|1⟩⟨2| - |2⟩⟨1|) \\\\\n",
    "gm8 = 1/√3 (|0⟩⟨0| + |1⟩⟨1| - 2|2⟩⟨2|)$\n",
    "\n",
    "These generators satisfy the commutation relations of the SU(3) Lie algebra, which is the symmetry group of the qutrit. The Gell-Mann matrices can be used to construct any unitary transformation on the qutrit, making them a useful tool for analyzing the behavior of qutrit systems in quantum mechanics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57735027  0.          0.        ]\n",
      " [ 0.          0.57735027  0.        ]\n",
      " [ 0.          0.         -1.15470054]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Gell-Mann matrices\n",
    "gm1 = np.kron(q0, q1.T) + np.kron(q1, q0.T)\n",
    "gm2 = -1j * (np.kron(q0, q1.T) - np.kron(q1, q0.T))\n",
    "gm3 = np.kron(q0, q0.T) - np.kron(q1, q1.T)\n",
    "gm4 = np.kron(q0, q2.T) + np.kron(q2, q0.T)\n",
    "gm5 = -1j * (np.kron(q0, q2.T) - np.kron(q2, q0.T))\n",
    "gm6 = np.kron(q1, q2.T) + np.kron(q2, q1.T)\n",
    "gm7 = -1j * (np.kron(q1, q2.T) - np.kron(q2, q1.T))\n",
    "gm8 = 1/np.sqrt(3) * (np.kron(q0, q0.T) + np.kron(q1, q1.T) - 2*np.kron(q2, q2.T))\n",
    "\n",
    "# Collect the Glenn-Mann matrices in a list\n",
    "generators = [gm1, gm2, gm3, gm4, gm5, gm6, gm7, gm8]\n",
    "\n",
    "# Print Glenn-Mann 8\n",
    "print(gm8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalised Hadamard for Qutrits\n",
    "\n",
    "Then defining the Hadamard operator for qutrits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadamard operator for qutrits:\n",
      "[[ 0.57735027+0.j   0.57735027+0.j   0.57735027+0.j ]\n",
      " [ 0.57735027+0.j  -0.28867513+0.5j -0.28867513-0.5j]\n",
      " [ 0.57735027+0.j  -0.28867513-0.5j -0.28867513+0.5j]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Hadamard operator for qutrits\n",
    "H = (1/np.sqrt(3)) * np.array([[1, 1, 1], [1, np.exp(2j*np.pi/3), np.exp(-2j*np.pi/3)], [1, np.exp(-2j*np.pi/3), np.exp(2j*np.pi/3)]])\n",
    "\n",
    "# Print the Hadamard operator\n",
    "print(\"Hadamard operator for qutrits:\")\n",
    "print(H)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Kernel\n",
    "\n",
    "To construct the quantum kernel, I'll use custom functions that leverage the principles of quantum computing to transform the input data into a high-dimensional Hilbert space. The quantum kernel captures complex and non-linear relationships between data points, making it advantageous for certain types of datasets, such as those with intricate decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding four features on a qutrit\n",
    "def encoding(vector):\n",
    "\n",
    "    sum = 0\n",
    "    for i in range(4):\n",
    "        sum = sum + (1j * vector[i] * generators[i]) \n",
    "\n",
    "    return np.dot(expm(sum), np.dot(H, q0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then defining the LZZ2 gate which is going to be used as an entanglement operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0. -2.]]\n",
      "[[ 4.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -4.  0.  0. -0.  0.  0. -0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -0.  0.  0. -0.  0.  0. -0.]\n",
      " [ 0.  0.  0.  0.  0.  0. -4. -0. -0.]\n",
      " [ 0.  0.  0.  0.  0.  0. -0. -0. -0.]\n",
      " [ 0.  0. -0.  0.  0. -0. -0. -0.  4.]]\n"
     ]
    }
   ],
   "source": [
    "LZ2 = gm3 + np.sqrt(3)*gm8\n",
    "LZZ2 = np.kron(LZ2, LZ2)\n",
    "print(LZ2)\n",
    "print(LZZ2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then defining the quantum kernel function which implements a quantum feature map that operates on two input data points, x1 and x2. The quantum feature map begins by encoding the first four and last four elements of x1 and x2 into two separate qutrit states using the encoding function. Then, an entanglement gate is applied between the three qutrits. The function then calculates the inner product of the quantum states, and its square magnitude is returned as the kernel value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(x1, x2):\n",
    "    \"\"\"The quantum kernel.\"\"\"\n",
    "    qutrit_1 = encoding(x1[:4])\n",
    "    qutrit_2 = encoding(x1[4:])\n",
    "\n",
    "    # Entanglement gate\n",
    "    entangle_gate = 1j*LZZ2\n",
    "\n",
    "    # Applying entanglement between the three qutrits\n",
    "    qutrit_1x2 = np.kron(qutrit_1, qutrit_2)\n",
    "    kron1 = np.dot(expm(entangle_gate), qutrit_1x2)\n",
    "\n",
    "    qutrit_1 = encoding(x2[:4])\n",
    "    qutrit_2 = encoding(x2[4:])\n",
    "\n",
    "    # Applying entanglement between the three qutrits\n",
    "    qutrit_1x2 = np.kron(qutrit_1, qutrit_2)\n",
    "    kron2 = np.dot(expm(entangle_gate), qutrit_1x2)\n",
    "\n",
    "    return np.real(np.dot(kron1.conj().T, kron2)**2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_matrix(A, B):\n",
    "    \"\"\"Compute the matrix whose entries are the kernel\n",
    "       evaluated on pairwise data from sets A and B.\"\"\"\n",
    "    return np.array([[kernel(a, b) for b in B] for a in A])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glass Dataset\n",
    "\n",
    "The Glass dataset consists of 214 samples, each characterized by nine features that describe the chemical composition of the glass. The objective is to classify the glass samples into one of six categories based on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (204, 8)\n",
      "Shape of y: (204,)\n",
      "x[0] feature example:  [-1.68077253  0.86007173  0.25775724  1.26371095 -0.69464426 -1.10258705\n",
      " -0.65368877 -0.15452212]\n",
      "y[0]:  3\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../Datasets/glass.data', delimiter=',', header=None)\n",
    "\n",
    "# A bit of data cleaning and selection is required in this dataset\n",
    "X_Class_1 = data.iloc[:68, :8]\n",
    "X_Class_2 = data.iloc[70:138, :8]\n",
    "X_Class_3 = data.iloc[146:, :8]\n",
    "X = pd.concat([X_Class_1, X_Class_2, X_Class_3], ignore_index=True)\n",
    "X = X.to_numpy()\n",
    "Class_1 = data.iloc[:68, 10]\n",
    "Class_2 = data.iloc[70:138, 10]\n",
    "Class_3 = pd.Series([3]*68)\n",
    "labels = pd.concat([Class_1, Class_2, Class_3], ignore_index=True)\n",
    "labels = labels.to_numpy()\n",
    "y = labels\n",
    "\n",
    "# scaling the inputs is important since the embedding we use is periodic\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "y_scaled = y\n",
    "\n",
    "print('Shape of X:', X_scaled.shape)\n",
    "print('Shape of y:', y_scaled.shape)\n",
    "print('x[0] feature example: ', X_scaled[0])\n",
    "print('y[0]: ', y_scaled[142])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the dataset into a training set and a test set into a 80-20 train-test split with equal representation of the two classes in both sets, I'll use the train_test_split function from sklearn.model_selection module with the stratify parameter set to the target variable y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts in training set: 163\n",
      "Class counts in test set: 41\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, stratify=y_scaled, random_state=42)\n",
    "\n",
    "# Use np.sum to count the number of instances of each class in both sets\n",
    "print(\"Class counts in training set:\", np.sum(y_train.shape))\n",
    "print(\"Class counts in test set:\", np.sum(y_test.shape))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical SVM\n",
    "\n",
    "For the classical SVM component, I'll rely on the popular scikit-learn library, a powerful toolset for machine learning in Python. The SVM aims to find the optimal hyperplane that separates data points of different classes while maximizing the margin between them. By combining the quantum kernel with the classical SVM, we can handle multi-class classification tasks effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=kernel_matrix).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then predicting on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9024390243902439"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svm.predict(X_test)\n",
    "accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results\n",
      "_____________________________________________\n",
      "\n",
      "Recall: 90.48%\n",
      "Precision: 90.43%\n",
      "Accuracy: 90.24%\n",
      "Macro Averaged F1-score: 90.21%\n",
      "_____________________________________________\n"
     ]
    }
   ],
   "source": [
    "# To be printed better\n",
    "y_pred = predictions\n",
    "y_true = y_test\n",
    "accuracy = accuracy_score(y_true, y_pred)* 100\n",
    "f1 = f1_score(y_true, y_pred, average='macro')* 100\n",
    "precision = precision_score(y_true, y_pred, average='macro')* 100\n",
    "recall = recall_score(y_true, y_pred, average='macro')* 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation Results\")\n",
    "print(\"_____________________________________________\")\n",
    "print(\n",
    "            f\"\\nRecall: {recall:.2f}%\"\n",
    "            f\"\\nPrecision: {precision:.2f}%\"\n",
    "            f\"\\nAccuracy: {accuracy:.2f}%\"\n",
    "            f\"\\nMacro Averaged F1-score: {f1:.2f}%\"\n",
    "            )\n",
    "print(\"_____________________________________________\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
