{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qutrit Quantum Kernel with Classical Support Vector Machine (SVM) for Seed Dataset\n",
    "\n",
    "In this notebook, I present the implementation of a quantum kernel combined with a classical SVM approach to tackle the Seed dataset. The Seed dataset is a multi-class classification problem containing samples of three different varieties of wheat seeds. The implementation process involves data preprocessing, quantum feature mapping, classical SVM training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.linalg import expm\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_moons\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qutrits\n",
    "\n",
    "Defining the qutrits that have three possible states, denoted as |0⟩, |1⟩, and |2⟩. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the qutrit states as column vectors\n",
    "q0 = np.array([[1], [0], [0]])\n",
    "q1 = np.array([[0], [1], [0]])\n",
    "q2 = np.array([[0], [0], [1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gell-Mann Matrices\n",
    "\n",
    "The generators of a qutrit are the operators that generate transformations on the qutrit states under some symmetry group. One common set of generators for a qutrit are the Gell-Mann matrices, which are a set of 8 Hermitian operators that span the space of 3x3 complex matrices:\n",
    "\n",
    "$gm1 = |0⟩⟨1| + |1⟩⟨0| \\\\\n",
    "gm2 = -i(|0⟩⟨1| - |1⟩⟨0|) \\\\\n",
    "gm3 = |0⟩⟨0| - |1⟩⟨1| \\\\\n",
    "gm4 = |0⟩⟨2| + |2⟩⟨0| \\\\\n",
    "gm5 = -i(|0⟩⟨2| - |2⟩⟨0|) \\\\\n",
    "gm6 = |1⟩⟨2| + |2⟩⟨1| \\\\\n",
    "gm7 = -i(|1⟩⟨2| - |2⟩⟨1|) \\\\\n",
    "gm8 = 1/√3 (|0⟩⟨0| + |1⟩⟨1| - 2|2⟩⟨2|)$\n",
    "\n",
    "These generators satisfy the commutation relations of the SU(3) Lie algebra, which is the symmetry group of the qutrit. The Gell-Mann matrices can be used to construct any unitary transformation on the qutrit, making them a useful tool for analyzing the behavior of qutrit systems in quantum mechanics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57735027  0.          0.        ]\n",
      " [ 0.          0.57735027  0.        ]\n",
      " [ 0.          0.         -1.15470054]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Gell-Mann matrices\n",
    "gm1 = np.kron(q0, q1.T) + np.kron(q1, q0.T)\n",
    "gm2 = -1j * (np.kron(q0, q1.T) - np.kron(q1, q0.T))\n",
    "gm3 = np.kron(q0, q0.T) - np.kron(q1, q1.T)\n",
    "gm4 = np.kron(q0, q2.T) + np.kron(q2, q0.T)\n",
    "gm5 = -1j * (np.kron(q0, q2.T) - np.kron(q2, q0.T))\n",
    "gm6 = np.kron(q1, q2.T) + np.kron(q2, q1.T)\n",
    "gm7 = -1j * (np.kron(q1, q2.T) - np.kron(q2, q1.T))\n",
    "gm8 = 1/np.sqrt(3) * (np.kron(q0, q0.T) + np.kron(q1, q1.T) - 2*np.kron(q2, q2.T))\n",
    "\n",
    "# Collect the Glenn-Mann matrices in a list\n",
    "generators = [gm1, gm2, gm3, gm4, gm5, gm6, gm7, gm8]\n",
    "\n",
    "# Print Glenn-Mann 8\n",
    "print(gm8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalised Hadamard for Qutrits\n",
    "\n",
    "Then defining the Hadamard operator for qutrits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadamard operator for qutrits:\n",
      "[[ 0.57735027+0.j   0.57735027+0.j   0.57735027+0.j ]\n",
      " [ 0.57735027+0.j  -0.28867513+0.5j -0.28867513-0.5j]\n",
      " [ 0.57735027+0.j  -0.28867513-0.5j -0.28867513+0.5j]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Hadamard operator for qutrits\n",
    "H = (1/np.sqrt(3)) * np.array([[1, 1, 1], [1, np.exp(2j*np.pi/3), np.exp(-2j*np.pi/3)], [1, np.exp(-2j*np.pi/3), np.exp(2j*np.pi/3)]])\n",
    "\n",
    "# Print the Hadamard operator\n",
    "print(\"Hadamard operator for qutrits:\")\n",
    "print(H)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Kernel\n",
    "\n",
    "To construct the quantum kernel, I'll use custom functions that leverage the principles of quantum computing to transform the input data into a high-dimensional Hilbert space. The quantum kernel captures complex and non-linear relationships between data points, making it advantageous for certain types of datasets, such as those with intricate decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding four features on a qutrit\n",
    "def encoding(vector):\n",
    "\n",
    "    sum = 0\n",
    "    for i in range(4):\n",
    "        sum = sum + (1j * vector[i] * generators[i]) \n",
    "\n",
    "    return np.dot(expm(sum), q0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then defining the entangling operator LZZ2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0. -2.]]\n",
      "[[ 4.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -4.  0.  0. -0.  0.  0. -0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -0.  0.  0. -0.  0.  0. -0.]\n",
      " [ 0.  0.  0.  0.  0.  0. -4. -0. -0.]\n",
      " [ 0.  0.  0.  0.  0.  0. -0. -0. -0.]\n",
      " [ 0.  0. -0.  0.  0. -0. -0. -0.  4.]]\n"
     ]
    }
   ],
   "source": [
    "LZ2 = gm3 + np.sqrt(3)*gm8\n",
    "LZZ2 = np.kron(LZ2, LZ2)\n",
    "print(LZ2)\n",
    "print(LZZ2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then defining the quantum kernel function which implements a quantum feature map that operates on two input data points, x1 and x2. The quantum feature map begins by encoding the first four and last four elements of x1 and x2 into two separate qutrit states using the encoding function. Then, an entanglement gate is applied between the three qutrits. The function then calculates the inner product of the quantum states, and its square magnitude is returned as the kernel value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(x1, x2):\n",
    "    \"\"\"The quantum kernel.\"\"\"\n",
    "    qutrit_1 = encoding(x1[:4])\n",
    "    qutrit_2 = encoding(x1[4:])\n",
    "\n",
    "    # Entanglement gate\n",
    "    entangle_gate = 1j*LZZ2\n",
    "\n",
    "    # Applying entanglement between the three qutrits\n",
    "    qutrit_1x2 = np.kron(qutrit_1, qutrit_2)\n",
    "    kron1 = np.dot(expm(entangle_gate), qutrit_1x2)\n",
    "\n",
    "    qutrit_1 = encoding(x2[:4])\n",
    "    qutrit_2 = encoding(x2[4:])\n",
    "\n",
    "    # Applying entanglement between the three qutrits\n",
    "    qutrit_1x2 = np.kron(qutrit_1, qutrit_2)\n",
    "    kron2 = np.dot(expm(entangle_gate), qutrit_1x2)\n",
    "\n",
    "    return np.real(np.dot(kron1.conj().T, kron2)**2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_matrix(A, B):\n",
    "    \"\"\"Compute the matrix whose entries are the kernel\n",
    "       evaluated on pairwise data from sets A and B.\"\"\"\n",
    "    return np.array([[kernel(a, b) for b in B] for a in A])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed Dataset \n",
    "\n",
    "The Seed dataset consists of 210 samples, each characterized by seven features that describe various geometric properties of the seeds. The goal is to classify these wheat seeds into one of three classes based on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (208, 7)\n",
      "Reduced  X: (208, 1)\n",
      "x[0] reduced example:  [0.64911212]\n",
      "x[0] reduced example:  [15.26  14.84   0.871  5.763  3.312  2.221  5.22 ]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../Datasets/seeds.txt', delimiter='\\t', header=None)\n",
    "data = data.fillna(1)\n",
    "\n",
    "X = data.iloc[:, :7].to_numpy()\n",
    "labels = data.iloc[:, 7].to_numpy(dtype=int)\n",
    "y = labels - 2\n",
    "\n",
    "# Perform PCA to reduce the dimensions to 4\n",
    "pca = PCA(n_components=1)\n",
    "reduced_X = pca.fit_transform(X)\n",
    "\n",
    "# Print the shapes of X and y to verify they match the expected dimensions\n",
    "print('Shape of X:', X.shape)\n",
    "print('Reduced  X:', reduced_X.shape)\n",
    "print('x[0] reduced example: ', reduced_X[0])\n",
    "print('x[0] reduced example: ', X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 8)\n"
     ]
    }
   ],
   "source": [
    "XR = np.concatenate((X, reduced_X), axis=1)\n",
    "\n",
    "# Verify the shape of the concatenated array\n",
    "print(XR.shape)  # Output: (200, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (208, 8)\n",
      "Shape of y: (208,)\n",
      "x[0] feature example:  [ 1.35444590e-01  2.08430865e-01 -1.62386721e-04  2.96821470e-01\n",
      "  1.34902457e-01 -9.98181036e-01 -3.93186748e-01  1.97746327e-01]\n",
      "y[0]:  1\n"
     ]
    }
   ],
   "source": [
    "# Scaling the inputs is important since the embedding we use is periodic\n",
    "scaler = StandardScaler().fit(XR)\n",
    "X_scaled = scaler.transform(XR)\n",
    "y_scaled = y\n",
    "\n",
    "print('Shape of X:', X_scaled.shape)\n",
    "print('Shape of y:', y_scaled.shape)\n",
    "print('x[0] feature example: ', X_scaled[0])\n",
    "print('y[0]: ', y_scaled[142])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the dataset into a training set and a test set into a 80-20 train-test split with equal representation of the two classes in both sets, I'll use the train_test_split function from sklearn.model_selection module with the stratify parameter set to the target variable y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts in training set: 166\n",
      "Class counts in test set: 42\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, stratify=y_scaled, random_state=42)\n",
    "\n",
    "# Use np.sum to count the number of instances of each class in both sets\n",
    "print(\"Class counts in training set:\", np.sum(y_train.shape))\n",
    "print(\"Class counts in test set:\", np.sum(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that the kernel of a data point with itself equals 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "print(kernel(X_train[0], X_train[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical SVM\n",
    "\n",
    "For the classical SVM component, I'll rely on the popular scikit-learn library, a powerful toolset for machine learning in Python. The SVM aims to find the optimal hyperplane that separates data points of different classes while maximizing the margin between them. By combining the quantum kernel with the classical SVM, we can handle multi-class classification tasks effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=kernel_matrix).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8809523809523809"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svm.predict(X_test)\n",
    "accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results\n",
      "_____________________________________________\n",
      "\n",
      "Recall: 88.10%\n",
      "Precision: 89.56%\n",
      "Accuracy: 88.10%\n",
      "Macro Averaged F1-score: 87.93%\n",
      "_____________________________________________\n"
     ]
    }
   ],
   "source": [
    "# To be printed better\n",
    "y_pred = predictions\n",
    "y_true = y_test\n",
    "accuracy = accuracy_score(y_true, y_pred)* 100\n",
    "f1 = f1_score(y_true, y_pred, average='macro')* 100\n",
    "precision = precision_score(y_true, y_pred, average='macro')* 100\n",
    "recall = recall_score(y_true, y_pred, average='macro')* 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation Results\")\n",
    "print(\"_____________________________________________\")\n",
    "print(\n",
    "            f\"\\nRecall: {recall:.2f}%\"\n",
    "            f\"\\nPrecision: {precision:.2f}%\"\n",
    "            f\"\\nAccuracy: {accuracy:.2f}%\"\n",
    "            f\"\\nMacro Averaged F1-score: {f1:.2f}%\"\n",
    "            )\n",
    "print(\"_____________________________________________\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
