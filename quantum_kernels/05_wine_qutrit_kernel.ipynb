{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qutrit Quantum Kernel with Classical Support Vector Machine (SVM) for Wine Dataset\n",
    "\n",
    "In this notebook, I present the implementation of a quantum kernel combined with a classical SVM approach to address the Wine dataset. The Wine dataset is a multi-class classification problem, containing samples from three different types of wines.\n",
    "\n",
    "The Wine dataset comprises 178 samples, each with 13 features that represent various chemical properties of the wines. The task is to classify these wines into one of three classes based on these features. The implementation process involves data preprocessing, quantum feature mapping, classical SVM training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.linalg import expm\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_moons\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qutrits\n",
    "\n",
    "Defining the qutrits that have three possible states, denoted as |0⟩, |1⟩, and |2⟩. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the qutrit states as column vectors\n",
    "q0 = np.array([[1], [0], [0]])\n",
    "q1 = np.array([[0], [1], [0]])\n",
    "q2 = np.array([[0], [0], [1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gell-Mann Matrices\n",
    "\n",
    "The generators of a qutrit are the operators that generate transformations on the qutrit states under some symmetry group. One common set of generators for a qutrit are the Gell-Mann matrices, which are a set of 8 Hermitian operators that span the space of 3x3 complex matrices:\n",
    "\n",
    "$gm1 = |0⟩⟨1| + |1⟩⟨0| \\\\\n",
    "gm2 = -i(|0⟩⟨1| - |1⟩⟨0|) \\\\\n",
    "gm3 = |0⟩⟨0| - |1⟩⟨1| \\\\\n",
    "gm4 = |0⟩⟨2| + |2⟩⟨0| \\\\\n",
    "gm5 = -i(|0⟩⟨2| - |2⟩⟨0|) \\\\\n",
    "gm6 = |1⟩⟨2| + |2⟩⟨1| \\\\\n",
    "gm7 = -i(|1⟩⟨2| - |2⟩⟨1|) \\\\\n",
    "gm8 = 1/√3 (|0⟩⟨0| + |1⟩⟨1| - 2|2⟩⟨2|)$\n",
    "\n",
    "These generators satisfy the commutation relations of the SU(3) Lie algebra, which is the symmetry group of the qutrit. The Gell-Mann matrices can be used to construct any unitary transformation on the qutrit, making them a useful tool for analyzing the behavior of qutrit systems in quantum mechanics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57735027  0.          0.        ]\n",
      " [ 0.          0.57735027  0.        ]\n",
      " [ 0.          0.         -1.15470054]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Gell-Mann matrices\n",
    "gm1 = np.kron(q0, q1.T) + np.kron(q1, q0.T)\n",
    "gm2 = -1j * (np.kron(q0, q1.T) - np.kron(q1, q0.T))\n",
    "gm3 = np.kron(q0, q0.T) - np.kron(q1, q1.T)\n",
    "gm4 = np.kron(q0, q2.T) + np.kron(q2, q0.T)\n",
    "gm5 = -1j * (np.kron(q0, q2.T) - np.kron(q2, q0.T))\n",
    "gm6 = np.kron(q1, q2.T) + np.kron(q2, q1.T)\n",
    "gm7 = -1j * (np.kron(q1, q2.T) - np.kron(q2, q1.T))\n",
    "gm8 = 1/np.sqrt(3) * (np.kron(q0, q0.T) + np.kron(q1, q1.T) - 2*np.kron(q2, q2.T))\n",
    "\n",
    "# Collect the Glenn-Mann matrices in a list\n",
    "generators = [gm1, gm2, gm3, gm4, gm5, gm6, gm7, gm8]\n",
    "\n",
    "# Print Glenn-Mann 8\n",
    "print(gm8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalised Hadamard for Qutrits\n",
    "\n",
    "Then defining the Hadamard operator for qutrits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadamard operator for qutrits:\n",
      "[[ 0.57735027+0.j   0.57735027+0.j   0.57735027+0.j ]\n",
      " [ 0.57735027+0.j  -0.28867513+0.5j -0.28867513-0.5j]\n",
      " [ 0.57735027+0.j  -0.28867513-0.5j -0.28867513+0.5j]]\n"
     ]
    }
   ],
   "source": [
    "# Define the Hadamard operator for qutrits\n",
    "H = (1/np.sqrt(3)) * np.array([[1, 1, 1], [1, np.exp(2j*np.pi/3), np.exp(-2j*np.pi/3)], [1, np.exp(-2j*np.pi/3), np.exp(2j*np.pi/3)]])\n",
    "\n",
    "# Print the Hadamard operator\n",
    "print(\"Hadamard operator for qutrits:\")\n",
    "print(H)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Kernel\n",
    "\n",
    "To construct the quantum kernel, I'll use custom functions that leverage the principles of quantum computing to transform the input data into a high-dimensional Hilbert space. The quantum kernel captures complex and non-linear relationships between data points, making it advantageous for certain types of datasets, such as those with intricate decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding four features on a qutrit\n",
    "def encoding(vector):\n",
    "\n",
    "    sum = 0\n",
    "    for i in range(4):\n",
    "        sum = sum + (1j * vector[i] * generators[i+4]) \n",
    "\n",
    "    return np.dot(expm(sum), q0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then defining the kernel function, which quantifies the similarity or correlation between the quantum states of x1 and x2 and serves as a critical component in quantum machine learning algorithms like Support Vector Machines (SVM) for classification tasks, where the quantum advantage lies in capturing non-linear relationships between data points in high-dimensional quantum spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(x1, x2):\n",
    "    \"\"\"The quantum kernel.\"\"\"\n",
    "    enc1 = encoding(x1[:4])\n",
    "    enc2 = encoding(x1[4:8])\n",
    "    enc3 = encoding(x1[8:12])\n",
    "    kron1 = np.kron(np.kron(enc1, enc2),enc3)\n",
    "    enc1 = encoding(x2[:4])\n",
    "    enc2 = encoding(x1[4:8])\n",
    "    enc3 = encoding(x1[8:12])\n",
    "    kron2 = np.kron(np.kron(enc1, enc2),enc3)\n",
    "    return np.real(np.dot(kron1.conj().T, kron2)**2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_matrix(A, B):\n",
    "    \"\"\"Compute the matrix whose entries are the kernel\n",
    "       evaluated on pairwise data from sets A and B.\"\"\"\n",
    "    return np.array([[kernel(a, b) for b in B] for a in A])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine dataset\n",
    "\n",
    "The Wine dataset is a multi-class classification problem, containing samples from three different types of wines. In the dataset ingestion step, we'll load the Wine dataset using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14.23   1.71   2.43  15.6  127.     2.8    3.06   0.28   2.29   5.64\n",
      "   1.04   3.92] 1\n",
      "Shape of X: (178, 12)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../Datasets/wine.data', delimiter=',', header=None)\n",
    "X = data.iloc[:, 1:13].to_numpy()\n",
    "labels = data.iloc[:, 0].to_numpy()\n",
    "y = labels-2\n",
    "print(X[0], y[162])\n",
    "\n",
    "# Print the shapes of X and y to verify they match the expected dimensions\n",
    "print('Shape of X:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.51861254 -0.5622498   0.23205254 -1.16959318  1.91390522  0.80899739\n",
      "  1.03481896 -0.65956311  1.22488398  0.25171685  0.36217728  1.84791957]\n",
      "Shape of X: (178, 12)\n",
      "Shape of y: (178,)\n",
      "x[0] feature example:  [ 1.51861254 -0.5622498   0.23205254 -1.16959318  1.91390522  0.80899739\n",
      "  1.03481896 -0.65956311  1.22488398  0.25171685  0.36217728  1.84791957]\n",
      "y[162]:  1\n"
     ]
    }
   ],
   "source": [
    "# Scaling the inputs is important since the embedding we use is periodic\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "y_scaled = y\n",
    "\n",
    "print(X_scaled[0])\n",
    "print('Shape of X:', X_scaled.shape)\n",
    "print('Shape of y:', y_scaled.shape)\n",
    "print('x[0] feature example: ', X_scaled[0])\n",
    "print('y[162]: ', y_scaled[162])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the dataset into a training set and a test set into a 80-20 train-test split with equal representation of the two classes in both sets, I'll use the train_test_split function from sklearn.model_selection module with the stratify parameter set to the target variable y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts in training set: 142\n",
      "Class counts in test set: 36\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, stratify=y_scaled, random_state=42)\n",
    "\n",
    "# Use np.sum to count the number of instances of each class in both sets\n",
    "print(\"Class counts in training set:\", np.sum(y_train.shape))\n",
    "print(\"Class counts in test set:\", np.sum(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that the kernel of a datapoint with itself equals 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel(X_train[0],X_train[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical SVM\n",
    "\n",
    "For the classical SVM component, I'll rely on the popular scikit-learn library, a powerful toolset for machine learning in Python. The SVM aims to find the optimal hyperplane that separates data points of different classes while maximizing the margin between them. By combining the quantum kernel with the classical SVM, we can handle multi-class classification tasks effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=kernel_matrix, decision_function_shape='ovo').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svm.predict(X_test)\n",
    "accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results\n",
      "_____________________________________________\n",
      "\n",
      "Recall: 88.57%\n",
      "Precision: 88.97%\n",
      "Accuracy: 88.89%\n",
      "Macro Averaged F1-score: 88.64%\n",
      "_____________________________________________\n"
     ]
    }
   ],
   "source": [
    "# To be printed better\n",
    "y_pred = predictions\n",
    "y_true = y_test\n",
    "accuracy = accuracy_score(y_true, y_pred)* 100\n",
    "f1 = f1_score(y_true, y_pred, average='macro')* 100\n",
    "precision = precision_score(y_true, y_pred, average='macro')* 100\n",
    "recall = recall_score(y_true, y_pred, average='macro')* 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation Results\")\n",
    "print(\"_____________________________________________\")\n",
    "print(\n",
    "            f\"\\nRecall: {recall:.2f}%\"\n",
    "            f\"\\nPrecision: {precision:.2f}%\"\n",
    "            f\"\\nAccuracy: {accuracy:.2f}%\"\n",
    "            f\"\\nMacro Averaged F1-score: {f1:.2f}%\"\n",
    "            )\n",
    "print(\"_____________________________________________\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
